{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from Models import ResNet\n",
    "from Datasets import load_mnist_dataset\n",
    "from Datasets import load_az_dataset\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading datasets...\n"
     ]
    }
   ],
   "source": [
    "# load the A-Z and MNIST datasets, respectively\n",
    "print(\"[INFO] loading datasets...\")\n",
    "(azData, azLabels) = load_az_dataset(\"Datasets/a_z_handwritten_data.csv\")\n",
    "(digitsData, digitsLabels) = load_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 25, 25, 25])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the MNIST dataset occupies the labels 0-9, so let's add 10 to every\n",
    "# A-Z label to ensure the A-Z characters are not incorrectly labeled\n",
    "# as digits\n",
    "azLabels += 10\n",
    "\n",
    "# stack the A-Z data and labels with the MNIST digits data and labels\n",
    "data = np.vstack([azData, digitsData])\n",
    "labels = np.hstack([azLabels, digitsLabels])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each image in the A-Z and MNIST digts datasets are 28x28 pixels;\n",
    "# however, the architecture we're using is designed for 32x32 images,\n",
    "# so we need to resize them to 32x32\n",
    "data = [cv2.resize(image, (32, 32)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "\n",
    "# add a channel dimension to every image in the dataset and scale the\n",
    "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "le = LabelBinarizer()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "\n",
    "# account for skew in the labeled data\n",
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "\tclassWeight[i] = classTotals.max() / classTotals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 8.376792698826597,\n",
       " 1: 7.340992763742541,\n",
       " 2: 8.272532188841202,\n",
       " 3: 8.097605377398123,\n",
       " 4: 8.473769050410317,\n",
       " 5: 9.15967052114684,\n",
       " 6: 8.409685863874346,\n",
       " 7: 7.928835870012341,\n",
       " 8: 8.472527472527473,\n",
       " 9: 8.310577752227651,\n",
       " 10: 4.169069935111752,\n",
       " 11: 6.671089063221043,\n",
       " 12: 2.4702037677816224,\n",
       " 13: 5.7060390763765545,\n",
       " 14: 5.0546328671328675,\n",
       " 15: 49.72055030094583,\n",
       " 16: 10.035577924331829,\n",
       " 17: 8.011221945137157,\n",
       " 18: 51.629464285714285,\n",
       " 19: 6.808548216178029,\n",
       " 20: 10.320364090665715,\n",
       " 21: 4.990937338166753,\n",
       " 22: 4.6875,\n",
       " 23: 3.0418200946870066,\n",
       " 24: 1.0,\n",
       " 25: 2.989762680316426,\n",
       " 26: 9.94924294562973,\n",
       " 27: 4.999567698426422,\n",
       " 28: 1.1942625828703608,\n",
       " 29: 2.5705712380529007,\n",
       " 30: 1.993415609487038,\n",
       " 31: 13.827116212338593,\n",
       " 32: 5.362110534124629,\n",
       " 33: 9.21954719387755,\n",
       " 34: 5.3250759738465785,\n",
       " 35: 9.51695194206715}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.20, stratify=labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "Img_aug = ImageDataGenerator(rotation_range=10,zoom_range=0.05,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.15,horizontal_flip=False,\n",
    "                         fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "Epochs = 50\n",
    "Learning_rate = 1e-1\n",
    "Batch_Size = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "#initialize and compile our deep neural network\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=Learning_rate, decay=Learning_rate / Epochs)\n",
    "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3),(64, 64, 128, 256), reg=0.0005)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "#print(\"[INFO] training network...\")\n",
    "#H = model.fit(aug.flow(trainX, trainY, batch_size=Batch_Size),validation_data=(testX, testY),\n",
    "#              steps_per_epoch=len(trainX) // Batch_Size,epochs=EPOCHS,\n",
    "#              class_weight=classWeight,\n",
    "#              verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of label names\n",
    "labelNames = \"0123456789\"\n",
    "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "labelNames = [l for l in labelNames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading handwriting OCR model...\n"
     ]
    }
   ],
   "source": [
    "# load the handwriting OCR model\n",
    "print(\"[INFO] loading handwriting OCR model...\")\n",
    "model = load_model(\"Models/handwriting.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.51      0.51      1381\n",
      "           1       0.97      0.98      0.97      1575\n",
      "           2       0.87      0.96      0.92      1398\n",
      "           3       0.98      0.99      0.99      1428\n",
      "           4       0.90      0.95      0.92      1365\n",
      "           5       0.87      0.88      0.88      1263\n",
      "           6       0.95      0.98      0.96      1375\n",
      "           7       0.96      0.99      0.97      1459\n",
      "           8       0.95      0.98      0.96      1365\n",
      "           9       0.96      0.98      0.97      1392\n",
      "           A       0.98      0.99      0.99      2774\n",
      "           B       0.98      0.98      0.98      1734\n",
      "           C       0.99      0.99      0.99      4682\n",
      "           D       0.95      0.95      0.95      2027\n",
      "           E       0.99      0.99      0.99      2288\n",
      "           F       0.99      0.96      0.97       232\n",
      "           G       0.97      0.93      0.95      1152\n",
      "           H       0.97      0.95      0.96      1444\n",
      "           I       0.97      0.95      0.96       224\n",
      "           J       0.98      0.96      0.97      1699\n",
      "           K       0.98      0.96      0.97      1121\n",
      "           L       0.98      0.98      0.98      2317\n",
      "           M       0.99      0.99      0.99      2467\n",
      "           N       0.99      0.99      0.99      3802\n",
      "           O       0.94      0.94      0.94     11565\n",
      "           P       1.00      0.99      0.99      3868\n",
      "           Q       0.96      0.97      0.97      1162\n",
      "           R       0.98      0.99      0.99      2313\n",
      "           S       0.98      0.98      0.98      9684\n",
      "           T       0.99      0.99      0.99      4499\n",
      "           U       0.98      0.99      0.99      5802\n",
      "           V       0.98      0.99      0.98       836\n",
      "           W       0.99      0.98      0.98      2157\n",
      "           X       0.99      0.99      0.99      1254\n",
      "           Y       0.98      0.94      0.96      2172\n",
      "           Z       0.96      0.90      0.93      1215\n",
      "\n",
      "    accuracy                           0.96     88491\n",
      "   macro avg       0.96      0.96      0.96     88491\n",
      "weighted avg       0.96      0.96      0.96     88491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=Batch_Size)\n",
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1), target_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"handwritting\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a plot that plots and saves the training history\n",
    "N = np.arange(0, Epochs)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our list of output images\n",
    "images = []\n",
    "\n",
    "# randomly select a few testing characters\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(49,)):\n",
    "\t# classify the character\n",
    "\tprobs = model.predict(testX[np.newaxis, i])\n",
    "\tprediction = probs.argmax(axis=1)\n",
    "\tlabel = labelNames[prediction[0]]\n",
    "\n",
    "\t# extract the image from the test data and initialize the text\n",
    "\t# label color as green (correct)\n",
    "\timage = (testX[i] * 255).astype(\"uint8\")\n",
    "\tcolor = (0, 255, 0)\n",
    "\n",
    "\t# otherwise, the class label prediction is incorrect\n",
    "\tif prediction[0] != np.argmax(testY[i]):\n",
    "\t\tcolor = (0, 0, 255)\n",
    "\n",
    "\t# merge the channels into one image, resize the image from 32x32\n",
    "\t# to 96x96 so we can better see it and then draw the predicted\n",
    "\t# label on the image\n",
    "\timage = cv2.merge([image] * 3)\n",
    "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "\t\tcolor, 2)\n",
    "\n",
    "\t# add the image to our list of output images\n",
    "\timages.append(image)\n",
    "\n",
    "# construct the montage for the images\n",
    "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
    "\n",
    "# show the output montage\n",
    "cv2.imshow(\"OCR Results\", montage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
